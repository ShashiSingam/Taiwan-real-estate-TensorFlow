{"cells":[{"metadata":{"trusted":true,"_uuid":"ca5c68c32a8b9f26ee3e2c7fd8ccc8b6ba48e8db"},"cell_type":"code","source":"\nfrom __future__ import print_function\nfrom IPython import display\nimport math\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nfrom matplotlib import pyplot as plt\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\nfrom sklearn import metrics\ntf.logging.set_verbosity(tf.logging.ERROR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c4de7bcd975b371b4bc19bdf392f92629544251"},"cell_type":"code","source":"#df = pd.read_csv('ml-100k/u.item', sep='|',  encoding='latin-1')\ndf = pd.read_csv (\"../input/Real_estate_valuation_data_set.csv\",sep=';',  error_bad_lines=False, encoding='latin-1')\ndf = df.reindex (np.random.permutation(df.index))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"31e2fada1c890b903df8c24d09ed25a0e082c065"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"84a31566a70cd1a455e3785379f8b914e462a407"},"cell_type":"code","source":"df.info()\ndf['Y house price of unit area'] = df['Y house price of unit area'].str.replace(\",\", \".\").astype (float)\n#df['X3 distance to the nearest MRT station'] = df['X3 distance to the nearest MRT station'].str.replace(\",\", \".\").astype (float)\ndf['X2 house age']= df['X2 house age'].str.replace(\",\", \".\" ).astype (float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d4847b42c99966f04a0f7bddb32aa94324b3acfc"},"cell_type":"code","source":"def preprocess_features (df):\n    selected_features = df [['X4 number of convenience stores',\n                             'X2 house age']]\n#     #df['X1 transaction date'].str.replace(\",\", \".\").astype (float)\n#     df['X2 house age']= df['X2 house age'].str.replace(\",\", \".\" ).astype (float)\n#     df['X3 distance to the nearest MRT station'] = df['X3 distance to the nearest MRT station'].str.replace(\",\", \".\").astype (float)\n#     #df['X4 number of convenience stores'].str.replace(\",\", \".\").astype (float)\n#     df['X5 latitude'] = df['X5 latitude'].str.replace(\",\", \".\").astype (float)\n#     df['X6 longitude'] = df['X6 longitude'].str.replace(\",\", \".\").astype (float)\n    \n    processed_features = selected_features.copy()\n    processed_features.rename (columns = {\"X4 number of convenience stores\" : \"X4_number_of_convenience_stores\", \n                                          \"X2 house age\" : \"X2_house_age\"}, inplace = True)\n    return processed_features\n\ndef preprocess_targets (df):\n    \n    output_targets = df[['Y house price of unit area']]\n    output_targets.rename (columns = {\"Y house price of unit area\" : \"Y_house_price_of_unit_area\"}, inplace = True)\n    return output_targets\n\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"da113ca13db01587829fd4e9281ec7f34ec4a900"},"cell_type":"code","source":"preprocess_targets (df.head(313))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6de7787b78a37a576fcd9c31796af01d9f0f8430"},"cell_type":"code","source":"# split_transaction_date = pd.DataFrame()\n# split_transaction_date = df['X1 transaction date'].str.split(',', expand = True)\n# #split_transaction_date.rename ({\"0\": \"year\", \"1\": \"month\"})\n# split_transaction_date.reset_index (inplace = True)\n# split_transaction_date.columns = ['null','year', 'month']\n# #split_transaction_date.head()\n# df_update = pd.concat ([df.drop ('X1 transaction date', axis = 1) , split_transaction_date.drop ('null', axis = 1)], axis = 1, sort = False )\n# df_update.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"403593b8dce8d5778dff231d0f3f64da4f0428d1"},"cell_type":"code","source":"#choose the first 313 examples for training\ntraining_examples = preprocess_features (df.head(313))\ntraining_targets = preprocess_targets (df.head(313))\n\n#choose the last 100 examples for testing\n\ntesting_examples = preprocess_features (df.tail(100))\ntesting_targets = preprocess_targets (df.tail(100))\n\n#checking whether we have done the right thing\nprint(\"Training examples summary:\")\ndisplay.display(training_examples.describe())\nprint(\"Training targets summary:\")\ndisplay.display(training_targets.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fdb165c293e8d5538178ce3e8b72a77d6e63c26f"},"cell_type":"code","source":"# construct feature columns\n\ndef construct_feature_columns (input_features):\n#     print (set([tf.feature_column.numeric_column(my_feature)\n#               for my_feature in input_features])\n    #The name of inout numerica features to use\n    return set([tf.feature_column.numeric_column(my_feature) for my_feature in input_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ed1c83f0dc7f6c5cf96ed926536dcc16f35614b4"},"cell_type":"code","source":"#training_examples\nconstruct_feature_columns (training_examples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ece8901128958843908433a5ad942cfc6a1d07b4"},"cell_type":"code","source":"#training_targets['Y house price of unit area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"401ef9b4b889aa6ce5bd429e6650d407c3e5ab09"},"cell_type":"code","source":"def my_input_fn (features, targets, batch_size = 1, shuffle = True, num_epochs = None ):\n    # input features\n    features = {key : np.array (value) for key,value in dict (features).items()}\n    \n    # contsruct a dataset\n    \n    ds = Dataset.from_tensor_slices ((features, targets))\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # shuffle\n    if shuffle:\n        ds = ds.shuffle(300)\n        \n    #return the next batch of data\n    \n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features,labels\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"14851e9313b7d1f56c187cb92bbaa4259a60110b"},"cell_type":"code","source":"def get_quantile_based_boundaries (feature_values, num_buckets):\n    boundaries = np.arrange (1.0, num_buckets)/ num_buckets\n    quantiles = feature_values.quantile (boundaries)\n    return [quantiles[q] for q in quantiles.keys()]\n#Divide households into 7 buckets\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ebac597fc2156633fa671287c13da58e511ee662"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"476054bece65971f4deade3dbd68e8b5e39a845f"},"cell_type":"code","source":"def model_train(learning_rate, steps, batch_size, training_examples, training_targets):\n    periods = 10\n    steps_per_period = steps/periods\n    print (steps_per_period)\n    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm (my_optimizer,5.0)\n    \n    linear_regressor = tf.estimator.LinearRegressor(\n                        feature_columns = construct_feature_columns (training_examples), \n                        optimizer=my_optimizer \n    )\n    \n    # create input functions\n    training_input_fn = lambda: my_input_fn (training_examples, training_targets ['Y_house_price_of_unit_area'] , batch_size = batch_size)\n    predict_training_input = lambda: my_input_fn (training_examples, training_targets ['Y_house_price_of_unit_area'] ,\n                                                 num_epochs = 1, shuffle = False)\n    #Train the model, but do so inside a loop so that we can periodically access\n    \n    print (\"Training model\")\n    print (\"RMSE on training data\")\n    \n    training_rmse = []\n    \n    for period in range (periods):\n        print (period)\n        #Train the model starting from prior state\n        linear_regressor.train (\n            input_fn = training_input_fn,\n            steps = steps_per_period )\n        \n        training_predictions = linear_regressor.predict (input_fn = predict_training_input)\n        training_predictions = np.array ([item['predictions'][0] for item in training_predictions])\n        \n        # compute traiing and validation loss\n        \n        training_root_mean_squared_error = math.sqrt (metrics.mean_squared_error (training_predictions, training_targets))\n        #print the current loss\n        print (\"period %0.2f and error %0.3f\" % (period,training_root_mean_squared_error))\n        \n        training_rmse.append (training_root_mean_squared_error)\n    print (\"Model training finished\")\n         # Output a graph of loss metrics over periods.\n    plt.ylabel(\"RMSE\")\n    plt.xlabel(\"Periods\")\n    plt.title(\"Root Mean Squared Error vs. Periods\")\n    plt.tight_layout()\n    plt.plot(training_rmse, label=\"training\")\n        \n    plt.legend()\n    plt.show()\n    return linear_regressor\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"606b8ef0cf3d3b5fe95a7d69848d75f6fafddcd9"},"cell_type":"code","source":"model_train (learning_rate = 0.01,\n            steps = 100,\n            batch_size = 1,\n            training_examples = training_examples,\n            training_targets = training_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e5f9acfc4d279f815bd79ec0869271787daf679f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}